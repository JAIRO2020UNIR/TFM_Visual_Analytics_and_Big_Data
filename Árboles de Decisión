# Modelo de Árboles de Decisión
# para predicción de cáncer de mama

# 1. Importación de librerías necesarias
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, roc_curve, auc,
    precision_recall_curve
)
import joblib  # para guardar y cargar el modelo entrenado

# ============================================
# 2. Cargar dataset
# ============================================
# El dataset de cáncer de mama de sklearn contiene 30 características numéricas
# relacionadas con medidas obtenidas de imágenes digitalizadas de masas mamarias.
data = load_breast_cancer()
X, y = data.data, data.target

# ============================================
# 3. División en entrenamiento y prueba
# ============================================
# Se utiliza 80% para entrenamiento y 20% para prueba.
# La estratificación mantiene la proporción de clases.
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ============================================
# 4. Creación y entrenamiento del modelo
# ============================================
# El modelo DecisionTreeClassifier aprende reglas de decisión a partir de los datos.
# El parámetro 'max_depth' controla la profundidad del árbol (para evitar sobreajuste).
model = DecisionTreeClassifier(
    criterion='entropy',  # mide la ganancia de información
    max_depth=5,          # profundidad máxima del árbol
    random_state=42
)
model.fit(X_train, y_train)

# ============================================
# 5. Predicciones
# ============================================
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]  # Probabilidad de clase positiva (benigno)

# ============================================
# 6. Métricas numéricas
# ============================================
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("===== MÉTRICAS DEL MODELO - ÁRBOLES DE DECISIÓN =====")
print(f"Accuracy  : {acc:.4f}")
print(f"Precisión : {prec:.4f}")
print(f"Sensibilidad (Recall): {rec:.4f}")
print(f"F1-score  : {f1:.4f}")
print("\nReporte de Clasificación:\n", classification_report(y_test, y_pred, target_names=data.target_names))

# ============================================
# 7. Matriz de Confusión (valores + gráfica)
# ============================================
cm = confusion_matrix(y_test, y_pred)
print("\nMatriz de Confusión:\n", cm)

plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens", xticklabels=data.target_names, yticklabels=data.target_names)
plt.xlabel("Predicción")
plt.ylabel("Real")
plt.title("Matriz de Confusión - Árbol de Decisión")
plt.show()

# ============================================
# 8. Curva ROC y AUC
# ============================================
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, color="green", label=f"AUC = {roc_auc:.4f}")
plt.plot([0,1], [0,1], color="gray", linestyle="--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Curva ROC - Árbol de Decisión")
plt.legend(loc="lower right")
plt.show()

# ============================================
# 9. Curva Precision-Recall
# ============================================
precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)

plt.figure(figsize=(6,5))
plt.plot(recalls, precisions, marker=".")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Curva Precision-Recall - Árbol de Decisión")
plt.show()

# ============================================
# 10. Visualización del Árbol de Decisión
# ============================================
plt.figure(figsize=(18,10))
plot_tree(model, filled=True, feature_names=data.feature_names, class_names=data.target_names)
plt.title("Visualización del Árbol de Decisión (Profundidad=5)")
plt.show()

# ============================================
# 11. Distribución de probabilidades
# ============================================
plt.figure(figsize=(6,5))
sns.histplot(y_prob[y_test==0], color="red", label="Maligno (0)", kde=True, stat="density", bins=25)
sns.histplot(y_prob[y_test==1], color="green", label="Benigno (1)", kde=True, stat="density", bins=25)
plt.xlabel("Probabilidad predicha")
plt.title("Distribución de Probabilidades por Clase - Árbol de Decisión")
plt.legend()
plt.show()

# ============================================
# 12. Guardar el modelo entrenado
# ============================================
joblib.dump(model, "modelo_arbol_decision.pkl")
print("\nModelo guardado como 'modelo_arbol_decision.pkl'")

# ============================================
# 13. Cargar el modelo para pruebas o producción
# ============================================
modelo_cargado = joblib.load("modelo_arbol_decision.pkl")

# ============================================
# 14. Prueba con un nuevo paciente 
# ============================================
nuevo_paciente = [14.2, 20.5, 92.3, 600.1, 0.11, 0.15, 0.08, 0.05, 0.18, 0.07,
                  0.35, 1.2, 2.5, 30.0, 0.007, 0.02, 0.02, 0.01, 0.02, 0.003,
                  16.1, 25.4, 104.3, 800.5, 0.15, 0.25, 0.12, 0.10, 0.20, 0.08]

nueva_prediccion = modelo_cargado.predict([nuevo_paciente])
probabilidades = modelo_cargado.predict_proba([nuevo_paciente])

print("\n===== PREDICCIÓN CON VALORES PERSONALIZADOS =====")
print("Predicción:", nueva_prediccion, "=>", data.target_names[nueva_prediccion][0])
print("Probabilidades:")
print(" - Maligno (0):", f"{probabilidades[0][0]:.4f}")
print(" - Benigno (1):", f"{probabilidades[0][1]:.4f}")
